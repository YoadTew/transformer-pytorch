# Transformer pytorch - Easy implementation of "attention is all you need"  

This project is a learning experience, and should be a clear implementation of the paper "[Attention is All You Need](https://arxiv.org/abs/1706.03762)" (Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, arxiv, 2017).

My Main goal here is to create a working, efficient and easy to understand 
implementation of the paper.

I hope new readers can understand the details of the transformer model through this project.

## Acknowledgments
To create this project, I used the following projects and blogs:
* http://peterbloem.nl/blog/transformers
* https://github.com/jadore801120/attention-is-all-you-need-pytorch
* https://github.com/pbloem/former
* https://www.youtube.com/watch?v=U0s0f995w14&ab_channel=AladdinPersson